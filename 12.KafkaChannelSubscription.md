# Adding Kafka Channel and Subscription

In this chapter we will learn to setup a Kafka channel to receive the events from an event source and subscribe a knative service to listen to those events.

## Prerequisites
* Knative Serving and Knative Eventing are deployed on your cluster using OpenShift Serverless Operator
* RedHat AMQ Integration Streams Operator is deployed and a kafka cluster `my-cluster` is deployed and running in `kafka` namespace
* You have a Knative service deployed. Add a knative service running `kn service create msgtxr-sl --image=image-registry.openshift-image-registry.svc:5000/kn-demo/msgtxr -l app.openshift.io/runtime=quarkus --env format=none`


## Set the default channel to Kafka Channel

In order to set up a kafka channel, your cluster administrator should set the `clusterDefault` to spin up `KafkaChannel`. 

Cluster administrator should edit the configmap `default-ch-webhook` in the namespace `knative-eventing` by running `oc edit cm default-ch-webhook -n knative-eventing` 

and change the `clusterDefault` from `InMemoryChannel` to `KafkaChannel` in the `data` section.

```
data:
  default-ch-config: |
    clusterDefault:
      apiversion: messaging.knative.dev/v1alpha1
      kind: KafkaChannel
```

## Create a channel in your namespace

Add a new channel named `testchannel-one` in the namespace `kn-demo` with the following spec

```
apiVersion: messaging.knative.dev/v1alpha1
kind: Channel
metadata:
  name: testchannel-one
```
by running

```
% oc create -f kafka/channel.yaml 

channel.messaging.knative.dev/testchannel-one created
```

Verify the channel created is a kafka channel by running `oc get channel`

```
% oc get channel
NAME                                            READY   REASON   URL                                                           AGE
channel.messaging.knative.dev/testchannel-one   True             http://testchannel-one-kn-channel.kn-demo.svc.cluster.local   47s

NAME                                                 READY   REASON   URL                                                           AGE
kafkachannel.messaging.knative.dev/testchannel-one   True             http://testchannel-one-kn-channel.kn-demo.svc.cluster.local   47s
```

Note the URL for this testchannel as we will be using that while setting up the source.

Also notice that a new topic `knative-messaging-kafka.kn-demo.testchannel-one` is added to the kafka cluster `my-cluster` in the namespace `kafka` by running 

```oc get kafkatopic -n kafka```


## Add an event source

Now let us create an event source that posts events to this channel. We will add a ping source by running

```
kn source ping create my-ping-source --data="from pingsource" \
--schedule="* * * * *" \
--sink=http://testchannel-one-kn-channel.kn-demo.svc.cluster.local
```
* `schedule` shows that an event is posted every minute
* `data` is the data that will be sent with the event
* `sink` is configured with the channel URL we noted above to post the events to the kafka channel

Verify that the ping source is created
```
 % kn source ping list
NAME             SCHEDULE    SINK   AGE   CONDITIONS   READY   REASON
my-ping-source   * * * * *          16s   6 OK / 6     True 
```

Also note that the ping source is deployed as a pod
```
% oc get po| grep Running
msgtxr-1-gg5bf                                                    1/1     Running     0          113m
pingsource-my-ping-source-38669b3c-352a-44ef-a7a7-8fe3a7b5m9xww   1/1     Running     0          44s
```

This pod produces events that are sent to the kafka channel.

## Add a subscription

Now let us create a subscription by adding knative service `msg-txr` as a subscriber to the kafka channel `testchannel-one`. Here is the spec

```
apiVersion: messaging.knative.dev/v1alpha1
kind: Subscription
metadata:
  name: event-subscription
spec:
  channel:
    apiVersion: messaging.knative.dev/v1alpha1
    kind: Channel     
    name: testchannel-one
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1alpha1
      kind: Service
      name: msgtxr-sl
```

Add the subscription by running

```
% oc create -f kafka/event-subscription.yaml 

subscription.messaging.knative.dev/event-subscription created
```

Verify subscription is created

```
% oc get subscriptions.messaging.knative.dev
NAME                 READY   REASON   AGE
event-subscription   True             3m3s
```

The knative service should now come up. Check the pod logs `oc logs -c user-container -f $(oc get po  -l serving.knative.dev/service=msgtxr-sl -o=jsonpath='{.items[0].metadata.name}')` to see the events being delivered

```
% oc logs -c user-container -f $(oc get po -l serving.knative.dev/service=msgtxr-sl -o=jsonpath='{.items[0].metadata.name}')
__  ____  __  _____   ___  __ ____  ______ 
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/ 
 -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \   
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/   
2020-05-15 22:56:08,242 INFO  [io.quarkus] (main) getting-started 1.0-SNAPSHOT (powered by Quarkus 1.3.2.Final) started in 0.009s. Listening on: http://0.0.0.0:8080
2020-05-15 22:56:08,242 INFO  [io.quarkus] (main) Profile prod activated. 
2020-05-15 22:56:08,242 INFO  [io.quarkus] (main) Installed features: [cdi, resteasy]
22:56:08.735 IN {"body":"from pingsource"} OUT {"body":"from pingsource"}
22:57:00.181 IN {"body":"from pingsource"} OUT {"body":"from pingsource"}
22:58:00.200 IN {"body":"from pingsource"} OUT {"body":"from pingsource"}

```

## Conclusion
In this chapter we learnt to set up a kafka channel, create a subscription from this channel to the knative service. We setup a ping source to deliver events to the kafka channel.

## Clean up

* Delete subscripton

```
oc delete -f kafka/event-subscription.yaml 
```
* Delete event source

```
kn source ping delete my-ping-source
```
* Delete kafka channel

```
oc delete -f kafka/channel.yaml
```
* Delete kafka topic
  
```
oc delete kafkatopic knative-messaging-kafka.kn-demo.testchannel-one -n kafka
```



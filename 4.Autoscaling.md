
# Autoscaling Serverless Application with Knative serving

## Update the Service to provide upper limit for scaling

When we trigger autoscaling we want to make ensure that there are upper limits for the application so that autoscaler stays within that range. Let us update our knative service to configure `max-scale` value that

```
$ kn service update dumpy-serverless --concurrency-target=10
Service 'dumpy-serverless' updated in namespace 'kn-demo'.
```
If you describe the service now, you will observe an annotation added to the service template ` autoscaling.knative.dev/target: "10"`.

```
$ kn service describe dumpy-serverless
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  annotations:
    serving.knative.dev/creator: kube:admin
    serving.knative.dev/lastModifier: kube:admin
  creationTimestamp: "2019-07-31T19:24:12Z"
  generation: 8
  name: dumpy-serverless
  namespace: kn-demo
  resourceVersion: "1160668"
  selfLink: /apis/serving.knative.dev/v1alpha1/namespaces/kn-demo/services/dumpy-serverless
  uid: c70e1486-b3c8-11e9-ae9d-0a79972b8a42
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/target: "10"
      creationTimestamp: null
    spec:
      containers:
      - image: image-registry.openshift-image-registry.svc:5000/kn-demo/dumpy
        name: user-container
        resources:
          limits:
            cpu: 2m
            memory: 10Mi
          requests:
            cpu: 2m
            memory: 10Mi
      timeoutSeconds: 300
...
...
...
```

## List Knative serving route
Get route from:
```
$ kn route list
NAME               URL                                                                        AGE     CONDITIONS   TRAFFIC
dumpy-serverless   http://dumpy-serverless.kn-demo.apps.cluster-8ddb.sandbox567.opentlc.com   24h     3 OK / 3     100% -> dumpy-serverless-9qr9m
```

## Start Load test

Open a 2nd terminal to run the following command:

```
watch 'oc get pod'
```

Make sure no running pod and start the load as shown below.
Run this command in a different terminal:
```
siege -r 1 -c 50 -t 30S "http://dumpy-serverless.kn-demo.apps.cluster-8ddb.sandbox567.opentlc.com"
```

In the 2nd terminal, you will get 5 pods. It is because we are sending 50 requests from the load test and each pod can only serves 10 pods.
```
Every 2.0s: oc get pod                                                                       MacBook-Pro: Thu Aug  1 15:33:25 2019

NAME                                                 READY   STATUS      RESTARTS   AGE
deploy-pipeline-run-7662c-build-km4qf-pod-f3560c     0/8     Completed   0          24h
deploy-pipeline-run-7662c-deploy-qmnc5-pod-08b9f5    0/2     Completed   0          24h
dumpy-1-deploy                                       0/1     Completed   0          24h
dumpy-serverless-9qr9m-deployment-7bb647885b-cs4bj   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-ksjsz   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-psfg5   2/2     Running     0          23s
dumpy-serverless-9qr9m-deployment-7bb647885b-wgx5h   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-wlbcz   2/2     Running     0          21s

```

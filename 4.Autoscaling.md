
# Autoscaling Serverless Application with Knative serving

## Prerequisites
* This lab uses `siege` command. So install that if you don't already have it. Run `$ siege -v` to check if it is already on your workstation.


## Update the Service to provide upper limit for scaling

Let us update our knative service to configure `concurrency-target` value that for when to scale up based on the concurrent number of incoming request. This is required to autoscale the application.

```
<<<<<<< HEAD
$ kn service update dumpy-serverless --concurrency-target=5
Service 'dumpy-serverless' updated in namespace 'kn-demo'.
```

If you describe the service now, you will observe an annotation added to the service template ` autoscaling.knative.dev/target: "5"`.
=======
$ kn service update dumpy-serverless --concurrency-target=10
Service 'dumpy-serverless' updated in namespace 'kn-demo'.
```
If you describe the service now, you will observe an annotation added to the service template ` autoscaling.knative.dev/target: "10"`.
>>>>>>> f0aee425692ffbc6a94c16285364eacab86def19

```
$ kn service describe dumpy-serverless
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  annotations:
<<<<<<< HEAD
    serving.knative.dev/creator: admin
    serving.knative.dev/lastModifier: admin
  creationTimestamp: "2019-07-31T19:06:06Z"
  generation: 6
  name: dumpy-serverless
  namespace: kn-demo
  resourceVersion: "4469325"
=======
    serving.knative.dev/creator: kube:admin
    serving.knative.dev/lastModifier: kube:admin
  creationTimestamp: "2019-07-31T19:24:12Z"
  generation: 8
  name: dumpy-serverless
  namespace: kn-demo
  resourceVersion: "1160668"
>>>>>>> f0aee425692ffbc6a94c16285364eacab86def19
  selfLink: /apis/serving.knative.dev/v1alpha1/namespaces/kn-demo/services/dumpy-serverless
  uid: c70e1486-b3c8-11e9-ae9d-0a79972b8a42
spec:
  template:
    metadata:
      annotations:
<<<<<<< HEAD
        autoscaling.knative.dev/target: "5"
=======
        autoscaling.knative.dev/target: "10"
>>>>>>> f0aee425692ffbc6a94c16285364eacab86def19
      creationTimestamp: null
    spec:
      containers:
      - image: image-registry.openshift-image-registry.svc:5000/kn-demo/dumpy
        name: user-container
        resources:
          limits:
            cpu: 2m
            memory: 10Mi
          requests:
            cpu: 2m
            memory: 10Mi
      timeoutSeconds: 300
...
...
...
```

<<<<<<< HEAD
The above command creates a new revision for the service. You can check there are two revisions now:

```
$ kn revision list
NAME                     SERVICE            AGE   CONDITIONS   READY   REASON
dumpy-serverless-7qr8q   dumpy-serverless   12m   3 OK / 4     True    
dumpy-serverless-xd6vp   dumpy-serverless   75m   3 OK / 4     True  
```

However if you check the knative route, it routes 100% of the traffic to the latest revision

```
$ kn route list
NAME               URL                                                          AGE   CONDITIONS   TRAFFIC
dumpy-serverless   http://dumpy-serverless.kn-demo.apps.first.40.ocpcloud.com   77m   3 OK / 3     100% -> dumpy-serverless-7qr8q
```



## Load the application 

Get the URL for your Knative Route.

```
export URL=$(kn route list  | awk  'NR>1 {print $2}')
```

Confirm that your application is scaled down to zero and you have no pods running. The command below should give you no results. If not wait a minute until your pods are scaled down to zero.

```
$ oc get po | grep Running
```

Let us load this application now by running siege. Have another window ready to watch the pods with `watch oc get po`

```
siege -r 1 -c 50 -t 30S $URL
```

You will quickly see that it spins up a bunch of pods.

```
Every 2.0s: oc get po                                                                                       Veers-MacBook-Pro-2: Thu Aug  1 15:44:04 2019

NAME                                                 READY   STATUS      RESTARTS   AGE
dumpy-serverless-8s72b-deployment-6f88c96cbb-255dh   2/2     Running     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-2htb7   0/2     Pending     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-5b5kn   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-5nr4g   0/2     Pending     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-5wv6r   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-74c8l   0/2     Pending     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-8fmrw   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-95dvf   0/2     Pending     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-9snhf   0/2     Pending     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-f8css   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-fc7tx   2/2     Running     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-hqxdv   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-kl65t   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-lbq4k   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-q77z7   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-rskz6   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-s6zbp   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-ss4gm   2/2     Running     0          14s
dumpy-serverless-8s72b-deployment-6f88c96cbb-tfjtj   2/2     Running     0          11s
dumpy-serverless-8s72b-deployment-6f88c96cbb-v9zkn   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-x5fc7   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-xfrdn   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-xhhhm   0/2     Pending     0          1s
dumpy-serverless-8s72b-deployment-6f88c96cbb-xjcgk   2/2     Running     0          11s
```

and in a couple of minutes all these pods will scale down.

But there were just too many pods coming up at the same time. Should we limit the number of pods that can come up. Let us update the service again to update the `max-scale`, upper limit for the number of pods to `5`

```
$ kn service update dumpy-serverless --max-scale=5
Service 'dumpy-serverless' updated in namespace 'kn-demo'.
```

Try running `siege` again and this time it will only scale to `5` instances maximum

```
Every 2.0s: oc get po                                                                                       Veers-MacBook-Pro-2: Thu Aug  1 15:47:36 2019

NAME                                                 READY   STATUS              RESTARTS   AGE
dumpy-serverless-mbhzp-deployment-5c7d899f87-d7fmp   0/2     ContainerCreating   0          8s
dumpy-serverless-mbhzp-deployment-5c7d899f87-ht8cg   0/2     ContainerCreating   0          8s
dumpy-serverless-mbhzp-deployment-5c7d899f87-lwzwb   2/2     Running             0          52s
dumpy-serverless-mbhzp-deployment-5c7d899f87-wftnj   0/2     ContainerCreating   0          8s
dumpy-serverless-mbhzp-deployment-5c7d899f87-zwt2s   0/2     ContainerCreating   0          8s
``` 

## Conclusion

In this lab we have learnt to set up our Knative Service for autoscaling.
=======
## List Knative serving route
Get route from:
```
$ kn route list
NAME               URL                                                                        AGE     CONDITIONS   TRAFFIC
dumpy-serverless   http://dumpy-serverless.kn-demo.apps.cluster-8ddb.sandbox567.opentlc.com   24h     3 OK / 3     100% -> dumpy-serverless-9qr9m
```

## Start Load test

Open a 2nd terminal to run the following command:

```
watch 'oc get pod'
```

Make sure no running pod and start the load as shown below.
Run this command in a different terminal:
```
siege -r 1 -c 50 -t 30S "http://dumpy-serverless.kn-demo.apps.cluster-8ddb.sandbox567.opentlc.com"
```

In the 2nd terminal, you will get 5 pods. It is because we are sending 50 requests from the load test and each pod can only serves 10 pods.
```
Every 2.0s: oc get pod                                                                       MacBook-Pro: Thu Aug  1 15:33:25 2019

NAME                                                 READY   STATUS      RESTARTS   AGE
deploy-pipeline-run-7662c-build-km4qf-pod-f3560c     0/8     Completed   0          24h
deploy-pipeline-run-7662c-deploy-qmnc5-pod-08b9f5    0/2     Completed   0          24h
dumpy-1-deploy                                       0/1     Completed   0          24h
dumpy-serverless-9qr9m-deployment-7bb647885b-cs4bj   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-ksjsz   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-psfg5   2/2     Running     0          23s
dumpy-serverless-9qr9m-deployment-7bb647885b-wgx5h   2/2     Running     0          21s
dumpy-serverless-9qr9m-deployment-7bb647885b-wlbcz   2/2     Running     0          21s

```
>>>>>>> f0aee425692ffbc6a94c16285364eacab86def19

# Adding Kafka source to Serverless Application

## Prerequisites
* Knative Serving and Knative Eventing are deployed on your cluster using OpenShift Serverless Operator
* RedHat AMQ Integration Streams Operator is deployed and a kafka cluster `my-cluster` is deployed and running in `kafka` namespace
* You have a Knative service deployed. Add a knative service running `kn service create msgtxr-sl --image=image-registry.openshift-image-registry.svc:5000/kn-demo/msgtxr -l app.openshift.io/runtime=quarkus --env format=none`
  

## Add Kafka Topic

This should be added to the same namespace where kafka cluster is running. So depending on who created kafka cluster, you may need to ask the owner of `kafka` namespace to create a topic.

Add a topic by creating a custom resource with the following spec

```
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: knative-demo-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 1
  config:
    retention.ms: 7200000
    segment.bytes: 1073741824
```
You can add this by navigating to `kafka` namespace using administration console, installed operators, finding `Red Hat Integration AMQ Streams` operator and creating a kafka topic.

Or you can run this command:

```
% oc create -f kafka/kafka-topic.yaml -n kafka

kafkatopic.kafka.strimzi.io/knative-demo-topic created
```
Verify by running `oc get kafkatopics -n kafka` and you should see `knative-demo-topic` in the list.

## Add a Kafka Source

We will now create a KafkaSource that connects the topic we created above to the our serverless service that acts as the sink. This way any messages posted to the topic will be delivered to the serverless application.

```
apiVersion: sources.knative.dev/v1alpha1
kind: KafkaSource
metadata:
  name: kafka-source
spec:
  bootstrapServers: 
   - my-cluster-kafka-bootstrap.kafka:9092 
  topics: 
   - knative-demo-topic
  sink:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: msgtxr-sl
```

* Note the bootstrapserver and topic which opoints to the topic we created for the kafka cluster in the `kafka` namespace
* Note the sink that points to knative service `msgtxr-sl`

Let us create this kafka source

```
% oc create -f kafka/kafka-source.yaml

kafkasource.sources.knative.dev/kafka-source created
```

Verify the kafka source that we just added
```
% oc get kafkasource.sources.knative.dev

NAME           TOPICS                 BOOTSTRAPSERVERS                          READY   REASON   AGE
kafka-source   [knative-demo-topic]   [my-cluster-kafka-bootstrap.kafka:9092]   True             2m54s
```
Also note that kafka source is now running as a pod

```
% oc get po | grep Running
kafkasource-kafka-source-4767db0c-73cc-46c2-ad3c-14b806058sfkx2   1/1     Running     0          10m
```

## Post Messages

We can now post messages to kafka topic to deliver to our serverless application.

Let us test the same by running a pod that allows us to post these messages. Start a `kafka-producer` pod with the following command

```
oc run kafka-producer -ti --image=strimzi/kafka:0.14.0-kafka-2.3.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap.kafka:9092 --topic knative-demo-topic
```
* Note  the broker and topic we are connecting to from this pod

This will connect you to the running pod and display a prompt `>`

Now start sending messages that will post to kafka topic.

```
If you don't see a command prompt, try pressing enter.
>hello world
>this is a message posted to kafka topic
>^C
```
**Note** you can exit the running pod by pressing Ctrl+C. 

Watch the pod logs for your serverless service and you will see the messages delivered there. **Note** you will have to check the logs before the serverless pod goes down.

```
__  ____  __  _____   ___  __ ____  ______ 
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/ 
 -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \   
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/   
2020-05-15 13:58:57,791 INFO  [io.quarkus] (main) getting-started 1.0-SNAPSHOT (powered by Quarkus 1.3.2.Final) started in 0.014s. Listening on: http://0.0.0.0:8080
2020-05-15 13:58:57,791 INFO  [io.quarkus] (main) Profile prod activated. 
2020-05-15 13:58:57,791 INFO  [io.quarkus] (main) Installed features: [cdi, resteasy]
13:58:58.309 IN hello world OUT MESSAGE TITLE CASED : "Hello World"
13:59:13.837 IN this is a message posted to kafka topic OUT MESSAGE TITLE CASED : "This Is A Message Posted To Kafka Topic"
```
## Conclusion

In this chapter, we have learnt to set up a kafka source, that reads messages from a kafka topic and delivers to a consumer that we configured as our knative serverless application.


## Clean up

* The test pod kafka-producer should remove itself if you pressed Ctrl+C, but if it timed out before you pressed it, you may have to delete that pod by running

```
% oc delete po kafka-producer

pod "kafka-producer" deleted
```
* Remove kafka source

```
% oc delete kafkasource.sources.knative.dev kafka-source

kafkasource.sources.knative.dev "kafka-source" deleted
```

* Remove kafka topic
  
```
% oc delete kafkatopic knative-demo-topic -n kafka

kafkatopic.kafka.strimzi.io "knative-demo-topic" deleted
``` 


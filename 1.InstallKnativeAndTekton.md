# Install  OpenShift Serverless, OpenShift Pipelines, Client Tools and AMQ Streams

This tutorial has been tested with the following version.
```
OCP 4.4.3
OpenShift Serverless Operator 1.7.0
OpenShift Pipelines Operator  0.11.2
kn client v0.13.2
tkn client v0.9.0
```
**Note:** OpenShift Pipelines is still Community and Knative Eventing is still in tech preview.

## Install Knative Serving, Knative Eventing 
Install OpenShift Serverless Operator as explained (here)[https://docs.openshift.com/container-platform/4.4/serverless/installing_serverless/installing-openshift-serverless.html]
* Install Knative Serving as explained (here)[https://docs.openshift.com/container-platform/4.4/serverless/installing_serverless/installing-knative-serving.html]
* Install Knative Eventing as explained (here)[https://docs.openshift.com/container-platform/4.4/serverless/installing_serverless/installing-knative-eventing.html]

## Install OpenShift Pipelines
* Select OpenShift Pipelines Operator provided by Red Hat, Community and install the operator

## Install CLI tools
* On the right top corner of your openshift console, click on `?` , navigate to `Command Line Tools` and download CLIs for `oc`, `kn` and `tkn`

![cli download](./images/1.clidownload.png)

* Add the CLI to your PATH
  
## Install Knative Kafka Operator
* Find `Knative Apache Kafka Operator` by Red Hat in the Operator Hub, and install the same
* In the `knative-eventing` namespace, create an Custom Resource for `Knative components for Apache Kafka` with the spec
  ```
  spec:
  bootstrapServers: 'my-cluster-kafka-bootstrap.kafka:9092'
  setAsDefaultChannelProvisioner: true
  ```
*Note* this is a default spec that configures bootstrap expecting a kafka cluster named `my-cluster` in the namespace `kafka`

* This CR adds following pods to `knative-eventin` namespace 
```
kafka-ch-controller-f9589648f-hqz6c         1/1     Running   0          7d4h
kafka-ch-dispatcher-64976f876b-6xh49        1/1     Running   7          6d8h
kafka-controller-manager-6fb468f444-5lmvt   1/1     Running   0          7d4h
kafka-webhook-66875c495-cb5s8               1/1     Running   0          7d4h
```


## Install AMQ Streams
* Find `Red Hat Integration - AMQ Streams` by Red Hat in the Operator Hub and install this cluster wide operator.
* Create a new project named `kafka`
* Create a new kafka cluster by instantiating `Kafka` custom resource in the `kafka` project
 You can choose the default specification for kafka cluster which creates a kafka cluster named `my-cluster` with 3 replicas.

 ```
 apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 2.4.0
    replicas: 3
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.4'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
 ```

*Note* In the previous step we installed Kafka Knative Serving that expects a kafka cluster in `kafka` namespace with a name `my-cluster`

* In a few minutes you will see a `my-cluster` running with the following pods

```
% oc get po -n kafka      
NAME                                         READY   STATUS    RESTARTS   AGE
my-cluster-entity-operator-f796fb9c4-djssr   3/3     Running   0          7d4h
my-cluster-kafka-0                           2/2     Running   1          7d4h
my-cluster-kafka-1                           2/2     Running   0          7d4h
my-cluster-kafka-2                           2/2     Running   0          7d4h
my-cluster-zookeeper-0                       2/2     Running   0          7d5h
my-cluster-zookeeper-1                       2/2     Running   0          7d5h
my-cluster-zookeeper-2                       2/2     Running   0          7d5h
```


